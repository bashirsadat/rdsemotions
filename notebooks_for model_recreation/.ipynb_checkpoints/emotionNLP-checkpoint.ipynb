{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1e493c-67fd-4303-9b2f-cf81e5a8dc27",
   "metadata": {},
   "source": [
    "+ Eotion Detection in TExt\n",
    "+ Text Classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee30f87-69fb-41aa-9948-7c640ad9ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EDA Pkgs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dac1de6-7a6d-40d4-8104-e2c7120ca6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Data Viz Pkgs\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1b4407-c9e6-44d0-9d4b-bd0a2396f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neattext"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached neattext-0.1.2-py3-none-any.whl (114 kB)\n",
      "Installing collected packages: neattext\n",
      "Successfully installed neattext-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "distutils: C:\\ProgramData\\Anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: C:\\ProgramData\\Anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: C:\\ProgramData\\Anaconda3\\Include\\UNKNOWN\n",
      "sysconfig: C:\\ProgramData\\Anaconda3\\Include\n",
      "WARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ltk (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install neattext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83abcdae-4898-4144-98e4-1c65644a38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Text Cleaning Pkgs\n",
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978ebda5-79d5-4ccc-ad58-c795bd5549d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML Pkgs\n",
    "# Estimators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Transformers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d226416e-d785-4d09-a185-dfee0a458759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "# df = pd.read_csv(\"data/emotion_dataset_2.csv\")\n",
    "df = pd.read_csv(\"data/emotion_dataset_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2701c9ef-d791-480d-a1a3-3e984cb04189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral                                             Why ? \n",
       "1      joy    Sage Act upgrade on my to do list for tommorow.\n",
       "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
       "3      joy   Such an eye ! The true hazel eye-and so brill...\n",
       "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d99cbe1-978f-4616-9b87-283d3d522319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Value Counts\n",
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38a92b-8d58-4bd7-a8d7-77b2ecc4b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd92d2-a674-4477-8b52-1a9bba234c07",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1508fb4-0041-4ab6-951b-0e60b499eb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_terms_in_bracket',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_terms_in_bracket',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fefe6c3-6fe8-43ec-a37e-cbce78b9de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User handles\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e0a603a-8d25-44fb-acf5-9755dfba46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dc16003-8de6-408f-926c-269d19dd2a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye ! true hazel eye-and brilliant ! Regular f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe.. hugggzzz u .! babe naamazed nga ako...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "      <td>gift! Hope like it! hand wear ! It'll warm! Lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "      <td>world didnt me..so world DEFINITELY cnt away!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "      <td>man robbed today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "      <td>Youu JEALOUSY, #Losing YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "      <td>think baby, dream time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                               Text  \\\n",
       "0       neutral                                             Why ?    \n",
       "1           joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2       sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3           joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4           joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "...         ...                                                ...   \n",
       "34787  surprise  @MichelGW have you gift! Hope you like it! It'...   \n",
       "34788       joy  The world didnt give it to me..so the world MO...   \n",
       "34789     anger                           A man robbed me today .    \n",
       "34790      fear  Youu call it JEALOUSY, I call it of #Losing YO...   \n",
       "34791   sadness  I think about you baby, and I dream about you ...   \n",
       "\n",
       "                                              Clean_Text  \n",
       "0                                                      ?  \n",
       "1                        Sage Act upgrade list tommorow.  \n",
       "2      WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...  \n",
       "3      eye ! true hazel eye-and brilliant ! Regular f...  \n",
       "4      ugh babe.. hugggzzz u .! babe naamazed nga ako...  \n",
       "...                                                  ...  \n",
       "34787    gift! Hope like it! hand wear ! It'll warm! Lol  \n",
       "34788    world didnt me..so world DEFINITELY cnt away!!!  \n",
       "34789                                 man robbed today .  \n",
       "34790                      Youu JEALOUSY, #Losing YOU...  \n",
       "34791                             think baby, dream time  \n",
       "\n",
       "[34792 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9847f3-c5cd-4733-ac27-1cd5db358c6f",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61705089-57bb-458f-b243-9560c25669e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features & Labels\n",
    "Xfeatures = df['Clean_Text']\n",
    "ylabels = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba40ec08-c539-451f-b1a2-97145000fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split Data\n",
    "x_train,x_test,y_train,y_test = train_test_split(Xfeatures,ylabels,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b8152-0155-4929-8d67-b46197b5c68a",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d89942ce-d287-4583-a11e-6664292c0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# LogisticRegression Pipeline\n",
    "pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b380aa5-a711-4ad8-a1e3-daba84220c58",
   "metadata": {},
   "source": [
    "# Train and Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25708087-a5ea-4737-bd85-d2319f5327c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipe_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aba1b61b-4f44-4215-bb57-6676017d7db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47462ce4-94f4-4834-884f-032ca379fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6200421536692853"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "pipe_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed3f31a4-6541-4606-b199-127b8c963d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make A Prediction\n",
    "ex1 = \"This book was so interesting it made me happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f3970c-adf8-451e-8fe9-43579b34d94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.predict([ex1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3c844a-80ed-45ec-8f15-dd1999348125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60398531e-03, 7.06101842e-03, 6.95872756e-03, 9.43790871e-01,\n",
       "        1.00433930e-04, 2.63455796e-02, 6.64743987e-05, 1.40729097e-02]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Prob\n",
    "pipe_lr.predict_proba([ex1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "915335b4-56d0-470c-9979-e2cd48f2ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'shame',\n",
       "       'surprise'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To Know the classes\n",
    "pipe_lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41b7c0f9-fa65-4757-bcf2-39295effdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model & Pipeline\n",
    "import joblib\n",
    "pipeline_file = open(\"emotion_classifier_pipe_lr_03_june_2021.pkl\",\"wb\")\n",
    "joblib.dump(pipe_lr,pipeline_file)\n",
    "pipeline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b97a51-b660-4fc1-be8c-206a8b4f6885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
